{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Lecci\u00f3n 4 - Sistemas de recomendaci\u00f3n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Objetivo\n",
      "El objetivo de esta lecci\u00f3n es entender como funcionan distintos m\u00e9todos para hacer recomendaciones.\n",
      "\n",
      "Nota: Esta lecci\u00f3n est\u00e1 basada en el Cap\u00edtulo 9 del libro Mining of Massive Datasets. Rajaraman, Leskovec and Ullman 2012 y en las notas del curso de M\u00e9todos Anal\u00edticos del 2013 por Felipe Gonzalez."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Sistemas de recomendaci\u00f3n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "El objetivo de un sistema de recomendaci\u00f3n es poder predecir elementos que podr\u00edan gustar a un usuario dadas sus preferencias.\n",
      "\n",
      "Existen dos tipos principales de sistemas de recomendaci\u00f3n: \n",
      "\n",
      "* Los basados en contenido, permiten genererar recomendaciones a partir de los atributos de los objetos a recomendar.\n",
      "* Los basados en filtrado colaborativo, permiten generar recomendaciones basados en la similitud entre objetos o usuarios.\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Recomendaci\u00f3n basada en contenido\n",
      "\n",
      "Para poder hacer recomendaciones de acuerdo al contenido de los elementos es necesario crear un perfil para cada uno de los elementos.\n",
      "\n",
      "Estos perfiles son definidos a partir de las caracter\u00edsticas de los elementos. Por ejemplo:\n",
      "\n",
      "* G\u00e9nero de un libro\n",
      "* A\u00f1o de una pel\u00edcula\n",
      "* Director\n",
      "* Marca o modelo de un objeto\n",
      "* Caracter\u00edsticas f\u00edsicas\n",
      "* Compositor\n",
      "\n",
      "Existen otras caracter\u00edsticas que no son tan evidentes pero que se pueden obtener de conjuntos como colecciones de art\u00edculos o de im\u00e1genes.\n",
      "\n",
      "#### Documentos de texto\n",
      "\n",
      "Una posibilidad para extraer las palabras que caracterizan a un documento es utilizar las palabras con mayor coeficiente TF.IDF para las palabras de un documento.\n",
      "\n",
      "El coeficiente TF.IDF nos da la relaci\u00f3n entre la frecuencia con la que aparecen los t\u00e9rminos en un documento (TF) y el inverso de la frecuencia con la que aparece dicho t\u00e9rmino en todos los documentos (IDF).\n",
      "\n",
      "$$\\textbf{TF}_{ij} = \\frac{f_{ij}}{\\text{max}_k f_{kj}}$$\n",
      "\n",
      "$$\\textbf{IDF}_{i} = \\text{log}\\frac{N}{n_i}$$\n",
      "\n",
      "La distancia entre estas caracter\u00edsticas, puede ser la distancia de Jaccard o distancia  Coseno\n",
      "\n",
      "#### Etiquetas\n",
      "\n",
      "Otra forma  de describir los elementos en una colecci\u00f3n es mediante el uso de etiquetas definidas por los usuarios. Un caso ejemplar es el uso que netflix hace de las categor\u00edas generales para recomendar las pel\u00edculas _streaming_ en contraste con el sistema de recomendaci\u00f3n que ten\u00edan para las pel\u00edculas por DVD.\n",
      "\n",
      "### Caracter\u00edsticas de los perfiles\n",
      "\n",
      "Para representar los perfiles de usuario utilizamos vectores de elementos.\n",
      "\n",
      "* Para valores discretos utilizamos vectores booleanos, uno por cada caracter\u00edstica\n",
      "* Lo mismo para las palabras generadas con el modelo TF.IDF\n",
      "* Para valores num\u00e9ricos utilizamos una entrada para cada tipo de valor\n",
      "    * Es importante escalar estos valores adecuadamente\n",
      "    * Se puede utilizar un factor $\\alpha$ \n",
      "    \n",
      "### Predecir recomendaciones\n",
      "\n",
      "Para crear un perfil de usuario promediammos los componentes de los vectores que representan los perfiles de elementos, para aquellos elementos por los que el usuario tiene preferencias.\n",
      "\n",
      "Para predecir si un usuario est\u00e1 interesado en un elemento calculamos la distancia coseno ente el vector que representa el perfil de usuario y los vectores que representan a los elementos.\n",
      "\n",
      "Como se vi\u00f3 en las lecciones anteriores es posible utilizar t\u00e9cnicas de LSH para encontrar los elementos cercanos.\n",
      "\n",
      "$$u(x,i) = cos(x,i) = \\frac{x\\cdot i}{||x||\\cdot|||i|}$$\n",
      "\n",
      "Es importante notar que este m\u00e9todo solo va a generar recomendaciones para los elementos contenidos en el perfil de cada usuario. \n",
      "\n",
      "Si bien por un lado este enfoque nos permite generar recomendaciones para elementos nuevos no nos permite generar recomendaciones para usuarios nuevos."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Filtrado colaborativo\n",
      "\n",
      "Es posible aprovechar la informaci\u00f3n generada por las preferencias de m\u00e1s de un usuario, a este enfoque se le conoce como _filtrado colaborativo_ ya que las preferencias de m\u00faltiples usuarios colaboran para generar una recomendacion.\n",
      "\n",
      "En general en los sistemas de recomendaci\u00f3n encontraremos dos tipos de elementos: usuarios y elementos.\n",
      "\n",
      "Para cada par usuario-elemento, la _matriz de utilidad_ tiene una entrada que representa la preferencia del usuario por dicho elemento.\n",
      "\n",
      "En en el siguiente ejemplo podemos observar las preferencias de los usuarios ${A \\ldots B}$ respecto a las pel\u00edculas ${P_1 \\ldots P_5}$\n",
      "\n",
      "<table>\n",
      "<tr><th></th><th>$P_1$</th><th>$P_2$</th><th>$P_3$</th><th>$P_4$</th><th>$P_5$</th><th>$P_6$</th><th>$P_7$</th></tr>\n",
      "<tr><td>A</td><td>4</td><td></td><td></td><td>5</td><td>1</td><td></td><td></td></tr>\n",
      "<tr><td>B</td><td>5</td><td>5</td><td>4</td><td></td><td></td><td></td><td></td></tr>\n",
      "<tr><td>C</td><td></td><td></td><td></td><td>2</td><td>4</td><td>5</td><td></td></tr>\n",
      "<tr><td>D</td><td></td><td>3</td><td></td><td></td><td></td><td></td><td>3</td></tr>\n",
      "</table>\n",
      "\n",
      "Esta matriz generalemente es muy rala ya que los usuarios solo tienen preferencias definidas para un n\u00famero muy peque\u00f1o de los elementos.\n",
      "\n",
      "Otro tipo de matriz es aquel en el que los usuarios no definen un valor num\u00e9rico sino que se consideran sus acciones de forma implicita (compra / no compra).\n",
      "\n",
      "<table>\n",
      "<tr><th></th><th>$P_1$</th><th>$P_2$</th><th>$P_3$</th><th>$P_4$</th><th>$P_5$</th></tr>\n",
      "<tr><td>A</td><td>1</td><td>0</td><td>0</td><td>1</td><td>1</td></tr>\n",
      "<tr><td>B</td><td>1</td><td>1</td><td>1</td><td>1</td><td>0</td></tr>\n",
      "<tr><td>C</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td></tr>\n",
      "<tr><td>D</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td></tr>\n",
      "</table>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from math import sqrt\n",
      "\n",
      "def cos(a,b):\n",
      "    asq = sqrt(sum([e * e for e in a]))\n",
      "    bsq = sqrt(sum([e * e for e in b]))\n",
      "    num = sum([l * m for (l,m) in zip(a,b)])\n",
      "    return num / (asq * bsq)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Medici\u00f3n de la similitud\n",
      "\n",
      "Una forma muy simple de medir la similitud ser\u00eda utilizando la distancia de Jaccard entre los conjuntos de cosas compradas, sin embargo este enfoque nos limita a no considerar las calificaciones entre los elementos.\n",
      "\n",
      "<table>\n",
      "<tr><th></th><th>B</th><th>C</th><th>D</th></tr>\n",
      "<tr><td>A</td><td>4/5</td><td>2/4</td><td>0</td></tr>\n",
      "<tr><td>B</td><td></td><td>0</td><td>3/4</td></tr>\n",
      "<tr><td>C</td><td></td><td></td><td>0</td></tr>\n",
      "</table>\n",
      "\n",
      "Esto nos genera una percepci\u00f3n equivocada ya que no obstante $A$ y $B$ ten\u00edan preferencias similares en t\u00e9rminos de distancia se encuentran m\u00e1s lejanos que  $A$ y $C$.\n",
      "\n",
      "#### Distancia Coseno\n",
      "\n",
      "Podemos utilizar distancia coseno si asignamos a las opciones en blanco un valor cero, bajo este modelo tenemos las siguientes distancias:\n",
      "\n",
      "<table>\n",
      "<tr><th></th><th>B</th><th>C</th><th>D</th></tr>\n",
      "<tr><td>A</td><td>0.38</td><td>0.322</td><td>0</td></tr>\n",
      "<tr><td>B</td><td></td><td>0</td><td>.435</td></tr>\n",
      "<tr><td>C</td><td></td><td></td><td>0</td></tr>\n",
      "</table>\n",
      "\n",
      "Es importante considerar que en este caso:\n",
      "\n",
      "* Las opciones en blanco est\u00e1n asignando una calificaci\u00f3n mas cercana a 1 que a 5\n",
      "* La existencia de de entradas comunes entre elementos genera valores para la distancia\n",
      "\n",
      "Se puede compensar este \u00faltimo efecto si consideramos un umbral $t$ y convertimos en _1_ los elementos mayor o igual de este umbral y en _blanco_ los que est\u00e9n debajo. Tomemos $t=3$\n",
      "\n",
      "<table>\n",
      "<tr><th></th><th>$P_1$</th><th>$P_2$</th><th>$P_3$</th><th>$P_4$</th><th>$P_5$</th><th>$P_6$</th><th>$P_7$</th></tr>\n",
      "<tr><td>A</td><td>1</td><td></td><td></td><td>1</td><td></td><td></td><td></td></tr>\n",
      "<tr><td>B</td><td>1</td><td>1</td><td>1</td><td></td><td></td><td></td><td></td></tr>\n",
      "<tr><td>C</td><td></td><td></td><td></td><td></td><td>1</td><td>1</td><td></td></tr>\n",
      "<tr><td>D</td><td></td><td>1</td><td></td><td></td><td></td><td></td><td>1</td></tr>\n",
      "</table>\n",
      "\n",
      "Aplicando distancia Coseno o Jacard sobre estos elementos nos da el mismo resultado:\n",
      "\n",
      "<table>\n",
      "<tr><th></th><th>B</th><th>C</th><th>D</th></tr>\n",
      "<tr><td>A</td><td>3/4</td><td>1</td><td>0</td></tr>\n",
      "<tr><td>B</td><td></td><td>0</td><td>3/4</td></tr>\n",
      "<tr><td>C</td><td></td><td></td><td>0</td></tr>\n",
      "</table>\n",
      "\n",
      "Hasta ahora esta matriz es la que nos da un resultado intuitivamente mejor.\n",
      "\n",
      "#### Distancia Coseno normalizada\n",
      "\n",
      "Podemos tambi\u00e9n normalizar las calificaciones de cada usuario si a cada entrada le restamos la media de sus calificaciones. Esto nos permite _centrar_ las calificaciones y convertir las calificaciones altas vs bajas de cada usuario en opuestas.\n",
      "\n",
      "<table>\n",
      "<tr><th></th><th>$P_1$</th><th>$P_2$</th><th>$P_3$</th><th>$P_4$</th><th>$P_5$</th><th>$P_6$</th><th>$P_7$</th></tr>\n",
      "<tr><td>A</td><td>2/3</td><td></td><td></td><td>5/3</td><td>-7/3</td><td></td><td></td></tr>\n",
      "<tr><td>B</td><td>1/3</td><td>1/3</td><td>-2/3</td><td></td><td></td><td></td><td></td></tr>\n",
      "<tr><td>C</td><td></td><td></td><td></td><td>-5/3</td><td>1/3</td><td>4/3</td><td></td></tr>\n",
      "<tr><td>D</td><td></td><td>0</td><td></td><td></td><td></td><td></td><td>0</td></tr>\n",
      "</table>\n",
      "\n",
      "Utilizando esta matriz encontramos resultados que son m\u00e1s consistentes con la intuici\u00f3n que ten\u00edamos:\n",
      "\n",
      "<table>\n",
      "<tr><th></th><th>B</th><th>C</th><th>D</th></tr>\n",
      "<tr><td>A</td><td>0.092</td><td>-0.559</td><td>0</td></tr>\n",
      "<tr><td>B</td><td></td><td>0</td><td>0</td></tr>\n",
      "<tr><td>C</td><td></td><td></td><td>0</td></tr>\n",
      "</table>\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Escalas de acuerdo/gusto y similitud\n",
      "\n",
      "En general el problema de la normalizaci\u00f3n nos sirve para tratar con el uso heterogeneo de las escalas num\u00e9ricas por parte de los usuarios, por ejemplo las personas pueden ser:\n",
      "\n",
      "* Barcos: 5,5,5,4,4,5\n",
      "* Estrictos: 2,3,3,1,1,2\n",
      "* No se compromete: 3,3,3,3,4\n",
      "* Discrimina: 5,4,5,1,2,4\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "M\u00ednimos cuadrados alternados"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "M\u00e1s all\u00e1 de poder recomendar ciertos elementos dadas las preferencias de un usuario, nos gustar\u00eda poder recomendar a los usuarios a partir de los gustos / preferencias de otros usuarios.\n",
      "\n",
      "Si tomamos la matriz del ejemplo anterior tenemos:\n",
      "\n",
      "<table>\n",
      "<tr><th></th><th>$P_1$</th><th>$P_2$</th><th>$P_3$</th><th>$P_4$</th><th>$P_5$</th><th>$P_6$</th><th>$P_7$</th></tr>\n",
      "<tr><td>A</td><td>4</td><td></td><td></td><td>5</td><td>1</td><td></td><td></td></tr>\n",
      "<tr><td>B</td><td>5</td><td>5</td><td>4</td><td></td><td></td><td></td><td></td></tr>\n",
      "<tr><td>C</td><td></td><td></td><td></td><td>2</td><td>4</td><td>5</td><td></td></tr>\n",
      "<tr><td>D</td><td></td><td>3</td><td></td><td></td><td></td><td></td><td>3</td></tr>\n",
      "</table>\n",
      "\n",
      "Podemos observar que esta matriz es rala, nuestro objetivo es encontrar un modelo que pueda predecir los valores no observados en el modelo.\n",
      "\n",
      "Una de las formas m\u00e1s populares de filtrado colaborativo es la factorizaci\u00f3n de matrices. En este modelo construimos una aproximaci\u00f3n de la matriz de bajo rango."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "La matriz $M$ contienen las calificaciones para los usuarios (renglones) y elementos (columnas). $M$ se puede aproximar como el producto de un modelo de usuarios $W$ y un modelo para los elementos $V$.\n",
      "\n",
      "Cada rengl\u00f3n $W[i]$ es un vector que representa los factores latentes del usuario $i$ y cada rengl\u00f3n en $V[j]$ representa los factores latentes del elemento $j$.\n",
      "\n",
      "El producto de $W[i] \\cdot V[j]^T$ es un escalar que aproxima la calificaci\u00f3n $R_{i,j}$. En general podemos decir que $M \\approx W \\cdot V^T$.\n",
      "\n",
      "Las matrices $W$ y $V$ se pueden construir resolviendo el siguiente problema de optimizaci\u00f3n, donde el objetivo es minimizar el error cuadr\u00e1tico entre la matriz original y la aproximaci\u00f3n, para aquellos elementos que son observados.\n",
      "\n",
      "$$(W,V) = \\text{arg min}_{W,V} \\sum_{(ij)\\in E}{(M_{ij} - W_i \\cdot V_j^T)^2} + ||W||_2 + ||V||_2$$\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": []
    }
   ],
   "metadata": {}
  }
 ]
}